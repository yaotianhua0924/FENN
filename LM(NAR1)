clc;
clear;
A=xlsread('data1.xlsx');
datatrain=A(1:144);%
datatest=A(133:end);%后
mu = mean(datatrain);
sig = std(datatrain);
dataTrainStandardized = (datatrain - mu) / sig;
dataTestStandardized=(datatest - mu) / sig;
% Solve an Autoregression Time-Series Problem with a NAR Neural Network
% Script generated by Neural Time Series app
% Created 05-Dec-2021 10:47:47
%
% This script assumes this variable is defined:
%
%   dataTrainStandardized - feedback time series.

T = tonndata(dataTrainStandardized,false,false);

% Choose a Training Function
trainFcn = 'trainlm';  % Levenberg-Marquardt backpropagation.
% Create a Nonlinear Autoregressive Network
a=4;%步长
feedbackDelays = 1:a;%
hiddenLayerSize = 34;%
net = narnet(feedbackDelays,hiddenLayerSize,'open',trainFcn);
% Choose Feedback Pre/Post-Processing Functions
% Settings for feedback input are automatically applied to feedback output
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
% Prepare the Data for Training and Simulation
[x,xi,ai,t] = preparets(net,{},{},T);
% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net.divideFcn = 'divideblock';  % Divide data randomly划分为连续板块
net.divideMode = 'time';  % Divide up every sample
net.divideParam.trainRatio = 760/1000;
net.divideParam.valRatio = 150/1000;
net.divideParam.testRatio = 90/1000;
% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean Squared Error
% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate', 'ploterrhist', ...
    'plotregression', 'plotresponse', 'ploterrcorr', 'plotinerrcorr'};
% Train the Network
[net,tr] = train(net,x,t,xi,ai);
% Test the Network
y = net(x,xi,ai);%
e = gsubtract(t,y);%
performance = perform(net,t,y);
% Recalculate Training, Validation and Test Performance
trainTargets = gmultiply(t,tr.trainMask);%
valTargets = gmultiply(t,tr.valMask);%
testTargets = gmultiply(t,tr.testMask);%
trainPerformance = perform(net,trainTargets,y);
valPerformance = perform(net,valTargets,y);
testPerformance = perform(net,testTargets,y);
% View the Network
view(net)
% Plots
% Uncomment these lines to enable various plots.
%figure, plotperform(tr)
%figure, plottrainstate(tr)
%figure, ploterrhist(e)
%figure, plotregression(t,y)
%figure, plotresponse(t,y)
%figure, ploterrcorr(e)
%figure, plotinerrcorr(x,e)
% Closed Loop Network
% Use this network to do multi-step prediction.
% The function CLOSELOOP replaces the feedback input with a direct
% connection from the output layer.
netc = closeloop(net);
netc.name = [net.name ' - Closed Loop'];
view(netc)
[xc,xic,aic,tc] = preparets(netc,{},{},T);
yc = netc(xc,xic,aic);
closedLoopPerformance = perform(net,tc,yc);
% Multi-step Prediction
% Sometimes it is useful to simulate a network in open-loop form for as
% long as there is known data T, and then switch to closed-loop to perform
% multistep prediction. Here The open-loop network is simulated on the
% known output series, then the network and its final delay states are
% converted to closed-loop form to produce predictions for 5 more
% timesteps.
[x1,xio,aio,t] = preparets(net,{},{},T);
[y1,xfo,afo] = net(x1,xio,aio);
[netc,xic,aic] = closeloop(net,xfo,afo);
[y2,xfc,afc] = netc(cell(0,5),xic,aic);
% Further predictions can be made by continuing simulation starting with
% the final input and layer delay states, xfc and afc.
% Step-Ahead Prediction Network
% For some applications it helps to get the prediction a timestep early.
% The original network returns predicted y(t+1) at the same time it is
% given y(t+1). For some applications such as decision making, it would
% help to have predicted y(t+1) once y(t) is available, but before the
% actual y(t+1) occurs. The network can be made to return its output a
% timestep early by removing one delay so that its minimal tap delay is now
% 0 instead of 1. The new network returns the same outputs as the original
% network, but outputs are shifted left one timestep.
nets = removedelay(net);
nets.name = [net.name ' - Predict One Step Ahead'];
view(nets)
[xs,xis,ais,ts] = preparets(nets,{},{},T);
ys = nets(xs,xis,ais);
stepAheadPerformance = perform(nets,ts,ys);
% Deployment
% Change the (false) values to (true) to enable the following code blocks.
% See the help for each generation function for more information.
if (false)
    % Generate MATLAB function for neural network for application
    % deployment in MATLAB scripts or with MATLAB Compiler and Builder
    % tools, or simply to examine the calculations your trained neural
    % network performs.
    genFunction(net,'myNeuralNetworkFunction');
    y = myNeuralNetworkFunction(x,xi,ai);
end
if (false)
    % Generate a matrix-only MATLAB function for neural network code
    % generation with MATLAB Coder tools.
    genFunction(net,'myNeuralNetworkFunction','MatrixOnly','yes');
    x1 = cell2mat(x(1,:));
    xi1 = cell2mat(xi(1,:));
    y = myNeuralNetworkFunction(x1,xi1);
end
if (false)
    % Generate a Simulink diagram for simulation or deployment with.
    % Simulink Coder tools.
    gensim(net);
end
%save LM.mat
y_double=cell2mat(y);
y_double= sig*y_double + mu;
plot(y_double);
hold on;
t_double=cell2mat(t);
t_double= sig*t_double + mu;
plot(t_double);
%-------------------------------------------------------------------------
yfit1=y_double(1:end-12);
y1=t_double(1:end-12);
num2=length(yfit1);
mse2= sqrt(sum((y1-yfit1).^2)) ./ num2;
mae2 = mean(abs(y1- yfit1));
rmse2= sqrt(mean((yfit1-y1).^2));
R2 = 1 - (sum((yfit1-y1).^2) / sum((y1-mean(y1)).^2));
disp(['2008-2018年BP神经网络拟合发病率均方误差MSE为：',num2str(mse2)])
disp(['2008-2018年BP神经网络拟合发病率平均绝对误差MAE为：',num2str(mae2)])
disp(['2008-2018年BP神经网络拟合发病率均方根误差RMSE为：',num2str(rmse2)])
yF1=y_double(end-11:end);
test1=t_double(end-11:end);
figure
plot(yF1,'r--','LineWidth',1.5)
hold on
plot(test1,'b','LineWidth',2)
axis tight
title('2019年SARIMA预测丙肝发病率曲线')
legend('预测值','真实值','Location','NorthWest')
hold off
num1=12;
mse1 = sqrt(sum((test1-yF1).^2)) ./ num1;
mae1 = mean(abs(test1- yF1));
rmse1 = sqrt(mean((yF1-test1).^2));
R1 = 1 - (sum((yF1-test1).^2) / sum((test1- mean(test1)).^2));
disp(['2019年预测发病率均方误差MSE为：',num2str(mse1)])
disp(['2019年预测发病率平均绝对误差MAE为：',num2str(mae1)])
disp(['2019年预测发病率均方根误差RMSE为：',num2str(rmse1)])
